{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243d9235-7a14-4412-ae96-555de1f70c95",
   "metadata": {},
   "source": [
    "### 1) How would you define Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca2472-9ad1-4da1-9126-aedb877c6457",
   "metadata": {},
   "source": [
    "Machine learning is a way for computer programs to improve their performance on a task over time given more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb062e2-0f2c-46f9-bd3b-b2da1b814762",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2) Can you name 4 types of problems where it shines?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88585eb1-f2e1-4d82-9620-30ff7eefa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine learning algorithms have had good results on problems such has spam detection in email, cancer diagnosis, fraudulent credit card transactions, and automatically driving vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b0ae1-55a8-4e02-a76a-570f1dd009f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3) What is a labeled training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f1b4b2-a785-4345-9996-592986c56481",
   "metadata": {},
   "outputs": [],
   "source": [
    "A labeled training set is a collection of data where one of the features of the data indicates the class the training example belongs to. A labeled training set is used in supervised learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ead7c5-c0da-427c-9e4e-e18f609aa3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4) What are the two most common supervised tasks?\n",
    "The two most common supervised learning tasks are regression and classification. In a regression problem we our prediciton is a scalar value. When we're trying to solve a classification problem, our output is either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e17186-61a3-4cb5-9282-387ac9080477",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5) Can you name 4 common unsupervised tasks?\n",
    "Common unsupervised tasks include clustering, visualization, dimensionality reduction and association rule learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17265f-7075-427c-aa80-fe8dd9e5f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6) What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains?\n",
    "I would use a reinforcement learning approach. Reinforcement learning is a system where an \"agent\" observes the environment, selects and performs actions, then recieves a reward or punishment based on the result of the action. Over time the agent learns by itself what is the most productive strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea50bb-4010-44d6-b485-59b7f2d4c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 7) What type of algorithm would you use to segment your customers into multiple groups?\n",
    "I would use some sort of clustering algorithm that can find the decision boundaries in the groups automatically. This is an unsupervised approach. However, if I already knew the categories of my customers, then I would choose a supervised approach and go with a classification algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c1531-289c-431a-9076-77c87e4b5afb",
   "metadata": {},
   "source": [
    "### 8) Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem?\n",
    "I would frame it as a supervised learning problem because humans have a general idea about what spam is and what it isn't. We can use this notion to create a labeled dataset for an algorithm to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c71f98-aeeb-44fd-b0c4-b5f55ffa33c9",
   "metadata": {},
   "source": [
    "### 9) What is an online learning system?\n",
    "An online learning system learns from new data on-the-fly. As a result, the system is trained incrementally either by using one example at a time or using a mini-batch approach. This keeps each learning step cheap and memory efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b1a14-0216-4f32-a0cc-c3b2d4ca3616",
   "metadata": {},
   "source": [
    "### 10) What is out-of-core learning?\n",
    "Out-of-core learning is used when a dataset is too large to fit into a computer's memory. The algorithm loads part of the data, runs a training step, then repeats the process until it has run on all the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39434fd8-cfe0-4eed-8a8a-4bb895147fbd",
   "metadata": {},
   "source": [
    "### 11) What type of learning algorithm relies on a similarity measure to make predictions?\n",
    "Instance-based learning algorithms use a measure of similarity to generalize to new cases. In an instance-based learning system, the algorithm learns the examples by heart, then uses the similarity measure to generalize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ef392-fa06-4bd0-85e8-664fdcef48dd",
   "metadata": {},
   "source": [
    "### 12) What is the difference between a model parameter and a learning algorithmâ€™s hyperparameter?\n",
    "A hyperparameter is a parameter of the learning algorithm, not the model. For example, in a simple linear regression problem our model is parameterized by `theta` which is a vector of weights. In order to find the best values for `theta` we have a cost function which is run repeatedly by the gradient descent algorithm. Gradient descent has a hyperparameter called `alpha` which is the learning rate of the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86a69b-20e3-4496-98ad-6c69c2ffe773",
   "metadata": {},
   "source": [
    "### 13) What do model based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?\n",
    "The goal for a model-based algorithm is to be able to generalize to new examples. To do this, model based algorithms search for optimal values for the model's parameters, often called `theta`. This searching, or \"learning\", is what machine learning is all about. Model-based system learn by minimizing a cost function that measures how bad the system is at making predicitons on new data, plus a penalty for model complexity if the model is regularized. To make a prediction, a new instance's features are fed into a hypothesis function which uses the minimized `theta` found by repeatedly running the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4f5ab-d2d6-40ca-b015-47c2c96a5e68",
   "metadata": {},
   "source": [
    "### 14) Can you name 4 of the main challenges in Machine Learning?\n",
    "* Not gathering enough data, or sampling noise. Sampling noise means we'll have non-representative data as a result of chance.\n",
    "\n",
    "* Using a dataset that is not representative of the cases you want to generalize to. This is called sampling bias. For example, if you want to train an algorithm with \"cat videos\", and all your videos are from YouTube, you're actually training an algorithm to learn about \"YouTube cat videos.\"\n",
    "\n",
    "* Your dataset is full out missing values, outliers, and noise (poor measurments).\n",
    "\n",
    "* The features in your dataset are irrelevant. Garbage in, garbage out. \n",
    "  - Feature selection - choose the most relevant features from your dataset\n",
    "  - Feature extraction - combine features in your dataset to generate a new, more useful feature\n",
    "  \n",
    "* When your model performs well on the training data, but not on test data, you've over fit your model. Models that suffer from overfitting do not generalize well to new examples. Overfitting happens when the model is too complex relative to the amount and noisiness of the data.\n",
    "  - Try simplyfying the model by reducing the number of features in the data or constraining the parameters by reducing the degrees of freedom.\n",
    "  - Gather more training data.\n",
    "  - Reduce noise in the training data by fixing errors and removing outliers.\n",
    "\n",
    "* When your model is too simple to learn the underlying structure of the data you've underfit your model.\n",
    "  - Select a more powerful model with more parameters\n",
    "  - Use feature engineering to feed better features to the model\n",
    "  - Reduce the constraints of the model (increase degrees of freedom, reduce regularization parameter, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235620cb-57d0-4e95-b714-e46f032abc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
